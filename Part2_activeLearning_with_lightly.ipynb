{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOrw+rApXYrYN9g+5z9lcTq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akanksha0911/Assignment-5-Continual-ML-and-Active-Learning/blob/main/Part2_activeLearning_with_lightly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **End to end demonstratation of active learning with lightly- Classification Task**"
      ],
      "metadata": {
        "id": "aopyudshf2UU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ref: https://docs.lightly.ai/tutorials/platform/tutorial_active_learning.html#active-learning"
      ],
      "metadata": {
        "id": "RLR0mxHeijJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used logistic regression on top of the embeddings as a classifier. This is the same as using the embedding model as a pretrained backbone and putting a single layer classification head on top of it while fine-tuning only the classification head on the labeled dataset, but keeping the backbone frozen. Since the embeddings are already computed, we can use them directly as input to the classification head."
      ],
      "metadata": {
        "id": "d-pFH9DffwzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This workflow has the following structure:\n",
        "\n",
        "1. Choose an initial subset of your dataset, e.g. using one of our selection strategies like the CORESET selection strategy. Label this initial subset and train your model on it.\n",
        "\n",
        "Next, the active learning loop starts:\n",
        "\n",
        "Train a classifier on the labeled set.\n",
        "\n",
        "Use the classifier to predict on the unlabeled set.\n",
        "\n",
        "Calculate active learning scores from the prediction.\n",
        "\n",
        "Use an active learning agent to choose the next samples to be labeled based on the scores.\n",
        "\n",
        "Update the labeled set to include the newly chosen samples and remove them from the unlabeled set."
      ],
      "metadata": {
        "id": "tm_cjekkgHBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used the clothing-dataset-small."
      ],
      "metadata": {
        "id": "P49WQeePgSlJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Downloading the dataset:**\n",
        "\n",
        "The datasetâ€™s images are RGB images with a few hundred pixels in width and height. They show clothes from 10 different classes, like dresses, hats or t-shirts. The dataset is already split into a train, test, and validation set, and all images for one class are put into one folder."
      ],
      "metadata": {
        "id": "Wio2GnSlggP3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xW2V046fXzGn"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/alexeygrigorev/clothing-dataset-small.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creation of the dataset on the Lightly Platform with embeddings**\n"
      ],
      "metadata": {
        "id": "bFnbYPNrhCLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install lightly"
      ],
      "metadata": {
        "id": "JcWXktJaX2QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!lightly-magic input_dir=\"./clothing-dataset-small/train\" trainer.max_epochs=0 token=\"9c33f696ce0cc1c2d0ab268254904105ae3669a2d75cdfa1\"     new_dataset_name=\"active_learning_clothing_dataset\" loader.num_workers=8\n"
      ],
      "metadata": {
        "id": "P2ZKIr2fYs5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xTE9pLyaKtN",
        "outputId": "7f06cad2-c966-471b-f005-1d61dcd88825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Active learning**"
      ],
      "metadata": {
        "id": "fq2j6jyXhHub"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNswY_5eZR7Z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "from typing import List, Dict, Tuple\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from lightly.active_learning.agents.agent import ActiveLearningAgent\n",
        "from lightly.active_learning.config.selection_config import SelectionConfig\n",
        "from lightly.active_learning.scorers.classification import ScorerClassification\n",
        "from lightly.api.api_workflow_client import ApiWorkflowClient\n",
        "from lightly.openapi_generated.swagger_client import SamplingMethod"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01oxqCyhZR7a"
      },
      "source": [
        "Define the dataset for the classifier based on the embeddings.csv\n",
        "The LogisticRegression classifier needs the embeddings as features for its classification.\n",
        "Thus we define a class to create such a dataset out of the embeddings.csv.\n",
        "It also allows to choose only a subset of all samples dependant on the filenames given.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-WgnceXZR7a"
      },
      "outputs": [],
      "source": [
        "class CSVEmbeddingDataset:\n",
        "    def __init__(self, path_to_embeddings_csv: str):\n",
        "        with open(path_to_embeddings_csv, 'r') as f:\n",
        "            data = csv.reader(f)\n",
        "\n",
        "            rows = list(data)\n",
        "            header_row = rows[0]\n",
        "            rows_without_header = rows[1:]\n",
        "\n",
        "            index_filenames = header_row.index('filenames')\n",
        "            filenames = [row[index_filenames] for row in rows_without_header]\n",
        "\n",
        "            index_labels = header_row.index('labels')\n",
        "            labels = [row[index_labels] for row in rows_without_header]\n",
        "\n",
        "            embeddings = rows_without_header\n",
        "            indexes_to_delete = sorted([index_filenames, index_labels], reverse=True)\n",
        "            for embedding_row in embeddings:\n",
        "                for index_to_delete in indexes_to_delete:\n",
        "                    del embedding_row[index_to_delete]\n",
        "\n",
        "        # create the dataset as a dictionary mapping from the filename to a tuple of the embedding and the label\n",
        "        self.dataset: Dict[str, Tuple[np.ndarray, int]] = \\\n",
        "            dict([(filename, (np.array(embedding_row, dtype=float), int(label)))\n",
        "                  for filename, embedding_row, label in zip(filenames, embeddings, labels)])\n",
        "\n",
        "    def get_features(self, filenames: List[str]) -> np.ndarray:\n",
        "        features_array = np.array([self.dataset[filename][0] for filename in filenames])\n",
        "        return features_array\n",
        "\n",
        "    def get_labels(self, filenames: List[str]) -> np.ndarray:\n",
        "        labels = np.array([self.dataset[filename][1] for filename in filenames])\n",
        "        return labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "futpTY2OZR7b"
      },
      "source": [
        "First we read the variables we set before as environment variables via the console\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAlXEmyCZR7b"
      },
      "outputs": [],
      "source": [
        "token = \"9c33f696ce0cc1c2d0ab268254904105ae3669a2d75cdfa1\"\n",
        "path_to_embeddings_csv = \"/content/lightly_outputs/2022-11-12/06-12-31/embeddings.csv\"\n",
        "dataset_id = \"636f3962bd19c4ff7601b735\"\n",
        "\n",
        "# We define the client to the Lightly Platform API\n",
        "api_workflow_client = ApiWorkflowClient(token=token, dataset_id=dataset_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nBJ3l_IZR7c"
      },
      "source": [
        "We define the dataset, the classifier and the active learning agent\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0ISmoC8ZR7c"
      },
      "outputs": [],
      "source": [
        "dataset = CSVEmbeddingDataset(path_to_embeddings_csv=path_to_embeddings_csv)\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "agent = ActiveLearningAgent(api_workflow_client=api_workflow_client,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpdTDcK6ZR7c"
      },
      "source": [
        "1. Choose an initial subset of your dataset.\n",
        "We want to start with 200 samples and use the CORESET selection strategy for selecting them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dC8zdB5uZR7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68ff1679-e888-4989-eb82-97166d53cfe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting the initial selection\n",
            "There are 200 samples in the labeled set.\n"
          ]
        }
      ],
      "source": [
        "print(\"Starting the initial selection\")\n",
        "selection_config = SelectionConfig(n_samples=200, method=SamplingMethod.CORESET, name='initial-selection')\n",
        "agent.query(selection_config=selection_config)\n",
        "print(f\"There are {len(agent.labeled_set)} samples in the labeled set.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVDfdb8EZR7d"
      },
      "source": [
        "2. Train a classifier on the labeled set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTie11oJZR7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53ae676b-c242-41b9-9135-c62023add3e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "labeled_set_features = dataset.get_features(agent.labeled_set)\n",
        "labeled_set_labels = dataset.get_labels(agent.labeled_set)\n",
        "classifier.fit(X=labeled_set_features, y=labeled_set_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aINe-g_SZR7e"
      },
      "source": [
        "3. Use the classifier to predict on the query set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1Lw-CvcZR7e"
      },
      "outputs": [],
      "source": [
        "query_set_features = dataset.get_features(agent.query_set)\n",
        "predictions = classifier.predict_proba(X=query_set_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf5P7_foZR7e"
      },
      "source": [
        "4. Calculate active learning scores from the prediction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0i1fDKLZR7e"
      },
      "outputs": [],
      "source": [
        "active_learning_scorer = ScorerClassification(model_output=predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLDjcNZMZR7f"
      },
      "source": [
        "5. Use an active learning agent to choose the next samples to be labeled based on the active learning scores.\n",
        "We want to sample another 100 samples to have 300 samples in total and use the active learning strategy CORAL for it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fEtG2u9ZR7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be7a7f39-e7e2-4ed9-8d59-25f6771b0b2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 300 samples in the labeled set.\n"
          ]
        }
      ],
      "source": [
        "selection_config = SelectionConfig(n_samples=300, method=SamplingMethod.CORAL, name='al-iteration-1')\n",
        "agent.query(selection_config=selection_config, al_scorer=active_learning_scorer)\n",
        "print(f\"There are {len(agent.labeled_set)} samples in the labeled set.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5a082pgZR7f"
      },
      "source": [
        "6. Update the labeled set to include the newly chosen samples and remove them from the unlabeled set.\n",
        "This is already done internally inside the ActiveLearningAgent - no work for you :)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uvzo9aIBZR7g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "412c2f19-5fd3-4ca3-c164-2b724d2d987f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on unlabeled set: 0.38078034682080925\n"
          ]
        }
      ],
      "source": [
        "labeled_set_features = dataset.get_features(agent.labeled_set)\n",
        "labeled_set_labels = dataset.get_labels(agent.labeled_set)\n",
        "classifier.fit(X=labeled_set_features, y=labeled_set_labels)\n",
        "\n",
        "# evaluate on unlabeled set\n",
        "unlabeled_set_features = dataset.get_features(agent.unlabeled_set)\n",
        "unlabeled_set_labels = dataset.get_labels(agent.unlabeled_set)\n",
        "accuracy_on_unlabeled_set = classifier.score(X=unlabeled_set_features, y=unlabeled_set_labels)\n",
        "print(f\"accuracy on unlabeled set: {accuracy_on_unlabeled_set}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can use the newly chosen labeled set to retrain classifier on it. I  evaluated it e.g. on the unlabeled set, or on embeddings of a test set, generated before. If we are not satisfied with the performance, we can run steps 2 to 5 again."
      ],
      "metadata": {
        "id": "Ipu0ui2Shhd7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*************************************************************"
      ],
      "metadata": {
        "id": "Xwg6FbT9htjY"
      }
    }
  ]
}